{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# String needed to access the data in the zipfiles stored at https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data\n",
    "\n",
    "url_15 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_2015.zip'\n",
    "start_str_15 = '2015/'\n",
    "\n",
    "url_16_q1 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2016.zip'\n",
    "start_str_16_q1 = 'data_Q1_2016/'\n",
    "\n",
    "url_16_q2 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2016.zip'\n",
    "start_str_16_q2 = 'data_Q2_2016/'\n",
    "\n",
    "url_16_q3 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2016.zip'\n",
    "start_str_16_q3 = 'data_Q3_2016/'\n",
    "\n",
    "url_16_q4 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q4_2016.zip'\n",
    "start_str_16_q4 = ''\n",
    "\n",
    "url_17_q1 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2017.zip'\n",
    "start_str_17_q1 = ''\n",
    "\n",
    "url_17_q2 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2017.zip'\n",
    "start_str_17_q2 = ''\n",
    "\n",
    "url_17_q3 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2017.zip'\n",
    "start_str_17_q3 = ''\n",
    "\n",
    "url_17_q4 = 'https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q4_2017.zip'\n",
    "start_str_17_q4 = 'data_Q4_2017/'\n",
    "\n",
    "list_url = [[[url_15,start_str_15]], \n",
    "            [[url_16_q1,start_str_16_q1], [url_16_q2,start_str_16_q2], [url_16_q3,start_str_16_q3], [url_16_q4,start_str_16_q4]], \n",
    "            [[url_17_q1,start_str_17_q1], [url_17_q2,start_str_17_q2], [url_17_q3,start_str_17_q3], [url_17_q4,start_str_17_q4]]\n",
    "           ]\n",
    "\n",
    "list_keys = [15, 16, 17]\n",
    "\n",
    "dict_zipfile = dict(zip(list_keys,list_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  What hard-disk model shall we look at?\n",
    "\n",
    "### The SMART metrics present in the dataset are model-dependent, thus the various models have to be treated differently. In this project we will focus on a single model. \n",
    "\n",
    "With this script we aim to capture the most convenient model to focus on. We deduce that the model ST4000DM000 is the most used throughout 2015, 2016, and 2017 with 37600 differend hard disks of which about 7% have failed.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We load the datasets and extract the relevant columns and save them in ModelsDetail_15, ModelsDetail_16, and ModelsDetail_17. The relevant columns are :\n",
    "\n",
    "date : The time stamp of the observations.\n",
    "\n",
    "serial_number : Uniquely identifies a hard-disk. It is used to determine the number of distinct entries.\n",
    "\n",
    "model : Identifies the model of the hard-disk. \n",
    "\n",
    "failure : A value in {0,1}. When a 1 is present, the hard disk has failed on the specific date and is removed from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_entries_and_failures( url, start_string = ''):\n",
    "    '''This function reads the zip file located at url, open it, read the columns needed to capture the ratio failures/entries'''\n",
    "    ListDF = []\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "    files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith(start_string))]\n",
    "\n",
    "    for file in files : \n",
    "        data = pd.read_csv(z.open(file))\n",
    "        data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "        ListDF.append(data2)\n",
    "    \n",
    "    df = pd.concat(ListDF, ignore_index = True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "def per_model_entries_and_failures (df) :   \n",
    "    '''Return dataframe with number of failures and unique serial numbers'''\n",
    "    FailuresPerModel = df.groupby('model')['failure'].sum()\n",
    "    EntriesPerModel = df.groupby('model')['serial_number'].unique()\n",
    "\n",
    "    ModelsDetail = pd.concat([EntriesPerModel,FailuresPerModel],axis=1)\n",
    "    return ModelsDetail\n",
    "    \n",
    "    \n",
    "def save_yearly_entries_and_failures( dict_url, year ) :\n",
    "    list_df = []\n",
    "\n",
    "    for url, start_string in dict_url[year] :\n",
    "\n",
    "        df = read_entries_and_failures(url, start_string)  \n",
    "        list_df = list_df + [df]\n",
    "        \n",
    "    if len(dict_zipfile[year]) > 1 :\n",
    "        df = pd.concat(list_df, ignore_index = True)\n",
    "        \n",
    "    print('In year ' + str(year) + ' there are ' + str(df.shape[0]) + ' entries.\\n')    \n",
    "        \n",
    "    return per_model_entries_and_failures(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In year 15 there are 17509251 entries.\n",
      "\n",
      "In year 16 there are 24471617 entries.\n",
      "\n",
      "In year 17 there are 30471787 entries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ModelsDetail_15 = save_yearly_entries_and_failures( dict_zipfile, 15 )\n",
    "ModelsDetail_16 = save_yearly_entries_and_failures( dict_zipfile, 16 )\n",
    "ModelsDetail_17 = save_yearly_entries_and_failures( dict_zipfile, 17 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For every year we saved the number of failures and an array of unique serial numbers\n",
    "\n",
    "We combine the information across the three years in a common dataset. Observe that the same hard disk may have been used across different years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ListDF_raw = [ModelsDetail_15.add_suffix('_15'), ModelsDetail_16.add_suffix('_16'), ModelsDetail_17.add_suffix('_17')]\n",
    "\n",
    "#df_raw = reduce(lambda x, y: pd.merge(x, y, on = 'model'), ListDF_raw)\n",
    "\n",
    "DfTot = pd.concat(ListDF_raw, axis = 1) \n",
    "\n",
    "DfTot.failure_15 = DfTot.failure_15.fillna(0) \n",
    "DfTot.failure_16 = DfTot.failure_16.fillna(0) \n",
    "DfTot.failure_17 = DfTot.failure_17.fillna(0) \n",
    "\n",
    "DfTot['failure_tot'] = DfTot.failure_15 + DfTot.failure_16 + DfTot.failure_17\n",
    "del DfTot['failure_15']\n",
    "del DfTot['failure_16']\n",
    "del DfTot['failure_17']\n",
    "\n",
    "DfTot['serial_number_tot'] = [np.hstack((DfTot.loc[mod,'serial_number_15'], DfTot.loc[mod,'serial_number_16'], DfTot.loc[mod,'serial_number_17'])) for mod in DfTot.index]\n",
    "\n",
    "del DfTot['serial_number_15']\n",
    "del DfTot['serial_number_16']\n",
    "del DfTot['serial_number_17']\n",
    "\n",
    "DfTot['entries_tot'] = [len(set(DfTot.loc[mod,'serial_number_tot'])) for mod in DfTot.index]\n",
    "\n",
    "del DfTot['serial_number_tot']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every model we have the number of distinct hard disks and the number of failures observed. \n",
    "We look at their ratio and filter the models for which too few hard disks have been sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failure_tot</th>\n",
       "      <th>entries_tot</th>\n",
       "      <th>ratio_entry_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WDC WD30EFRX</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1261</td>\n",
       "      <td>0.096749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST3000DM001</th>\n",
       "      <td>106.0</td>\n",
       "      <td>1170</td>\n",
       "      <td>0.090598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST4000DM000</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>36700</td>\n",
       "      <td>0.070572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST31500541AS</th>\n",
       "      <td>112.0</td>\n",
       "      <td>1693</td>\n",
       "      <td>0.066155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi HDS723030ALA640</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.043222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi HDS722020ALA330</th>\n",
       "      <td>152.0</td>\n",
       "      <td>4683</td>\n",
       "      <td>0.032458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST6000DX000</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1938</td>\n",
       "      <td>0.030960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi HDS5C3030ALA630</th>\n",
       "      <td>96.0</td>\n",
       "      <td>4608</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi HDS5C4040ALE630</th>\n",
       "      <td>42.0</td>\n",
       "      <td>2660</td>\n",
       "      <td>0.015789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST8000DM002</th>\n",
       "      <td>141.0</td>\n",
       "      <td>10029</td>\n",
       "      <td>0.014059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGST HMS5C4040ALE640</th>\n",
       "      <td>97.0</td>\n",
       "      <td>8661</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGST HMS5C4040BLE640</th>\n",
       "      <td>135.0</td>\n",
       "      <td>16306</td>\n",
       "      <td>0.008279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST8000NM0055</th>\n",
       "      <td>88.0</td>\n",
       "      <td>14510</td>\n",
       "      <td>0.006065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST10000NM0086</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST12000NM0007</th>\n",
       "      <td>17.0</td>\n",
       "      <td>7244</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         failure_tot  entries_tot  ratio_entry_failures\n",
       "WDC WD30EFRX                   122.0         1261              0.096749\n",
       "ST3000DM001                    106.0         1170              0.090598\n",
       "ST4000DM000                   2590.0        36700              0.070572\n",
       "ST31500541AS                   112.0         1693              0.066155\n",
       "Hitachi HDS723030ALA640         44.0         1018              0.043222\n",
       "Hitachi HDS722020ALA330        152.0         4683              0.032458\n",
       "ST6000DX000                     60.0         1938              0.030960\n",
       "Hitachi HDS5C3030ALA630         96.0         4608              0.020833\n",
       "Hitachi HDS5C4040ALE630         42.0         2660              0.015789\n",
       "ST8000DM002                    141.0        10029              0.014059\n",
       "HGST HMS5C4040ALE640            97.0         8661              0.011200\n",
       "HGST HMS5C4040BLE640           135.0        16306              0.008279\n",
       "ST8000NM0055                    88.0        14510              0.006065\n",
       "ST10000NM0086                    3.0         1225              0.002449\n",
       "ST12000NM0007                   17.0         7244              0.002347"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DfTot['ratio_entry_failures'] = DfTot['failure_tot'].divide(DfTot['entries_tot'], axis = 'rows')\n",
    "DfTot.sort_values('ratio_entry_failures', inplace=True, ascending =False)\n",
    "\n",
    "DfTot[DfTot['entries_tot'] > 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each brand has a different way of measuring the SMART metrics. For every model we need to understand which metrics are important and which are not. \n",
    "\n",
    "We now select a model and look at the data in the 2015 time frame. This is needed to obtain a mask that will be used to extract only the columns relevant to a specific model. \n",
    "\n",
    "Every model is associated with different SMART metrics. Moreover, for every relevant SMART metric we will work with the normalized value (in between 0 and 100/200/260 depending on the metric, the higher the better in tems of performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (2a) Check whether a SMART metric is relevant\n",
    "def is_relevant(col, thresh_diff = 20, thresh_var = 1) :\n",
    "    ''' Given a column of the DataFrame, decide whether it is relevant or not'''\n",
    "    diff = col.max() - col.min()\n",
    "    var = col.var()\n",
    "    mincol = col.min()\n",
    "    if mincol > 99 :\n",
    "        return False\n",
    "    if (diff > thresh_diff) | (var > thresh_var):\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## The following functions are needed in order to build a mask for any specific model.\n",
    "\n",
    "# (1) Read the datase associated to a model and a specific mask.\n",
    "def read_model_and_rel_cols (mod_name, rel_cols, DictUrl, year):\n",
    "    ''' This function reads the zip file of the year, open it, read the columns associated to a model and \n",
    "    the relevant columns '''\n",
    "    ListDF = []\n",
    "    \n",
    "    for url, start_string in DictUrl[year] :\n",
    "        r = requests.get(url)\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith(start_string))]\n",
    "        for file in files : \n",
    "            data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "            data2 = data[data['model'] == mod_name]\n",
    "            data3 = data2.iloc[:,rel_cols]\n",
    "            ListDF.append(data3)\n",
    "    \n",
    "    df = pd.concat(ListDF, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# (2) Return the SMART metrics with no NaN values and relevant variance.\n",
    "def find_relevant_cols(df, thresh_diff = 20, thresh_var = 1) :\n",
    "    ''' For the various SMART metrics return True only if the metric is considered by a specific model, i.e. the \n",
    "    relative values are not NaN and if the metric is relevant, i.e., the normalized range (max - min) is larger \n",
    "    than thresh'''\n",
    "    non_na_cols = (df.isnull().sum() == 0)\n",
    "        \n",
    "    res_bool = []\n",
    "        \n",
    "    for col in df.columns :\n",
    "        if non_na_cols[col] == True :\n",
    "            res_bool = res_bool + [is_relevant(df[col])]\n",
    "        else :\n",
    "            res_bool = res_bool + [False]\n",
    "    return res_bool\n",
    "    \n",
    "    \n",
    "# (3) Build the mask given the result of RelevantCols    \n",
    "def build_mask(rel_cols) :\n",
    "    ''' Esclude all raw columns and all the normalized columns not relevant for a specific model '''\n",
    "    \n",
    "    rel_cols_double = [val for val in rel_cols for _ in (0, 1)] \n",
    "    \n",
    "    return [a and b for a, b in zip(rel_cols_double, normalized_cols)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the model you want to work with. (ex:'Hitachi HDS722020ALA330', 'ST8000DM002')\n",
    "\n",
    "#ModelName = 'ST8000DM002' \n",
    "ModelName = 'Hitachi HDS722020ALA330' \n",
    "\n",
    "## normalized_cols has 'False' in correspondence of a column with a raw value and 'True' of a col with a normalized value\n",
    "normalized_cols = [True, False] # For each SMART metric the columns are ordered as Normalized,Raw,Normalized,Raw,...\n",
    "\n",
    "normalized_cols = normalized_cols*45 # ... and there are 45 SMART metrics\n",
    "\n",
    "# [date, serial number, model, capacity, failure] + SMART metrics\n",
    "cols = [False, False, False, False, False] + normalized_cols \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = read_model_and_rel_cols (ModelName, cols, dict_zipfile, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_2_normalized</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>smart_5_normalized</th>\n",
       "      <th>smart_7_normalized</th>\n",
       "      <th>smart_8_normalized</th>\n",
       "      <th>smart_9_normalized</th>\n",
       "      <th>smart_10_normalized</th>\n",
       "      <th>smart_11_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_225_normalized</th>\n",
       "      <th>smart_226_normalized</th>\n",
       "      <th>smart_240_normalized</th>\n",
       "      <th>smart_241_normalized</th>\n",
       "      <th>smart_242_normalized</th>\n",
       "      <th>smart_250_normalized</th>\n",
       "      <th>smart_251_normalized</th>\n",
       "      <th>smart_252_normalized</th>\n",
       "      <th>smart_254_normalized</th>\n",
       "      <th>smart_255_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>930850.000000</td>\n",
       "      <td>930850.000000</td>\n",
       "      <td>930850.000000</td>\n",
       "      <td>930850.0</td>\n",
       "      <td>930850.000000</td>\n",
       "      <td>930850.000000</td>\n",
       "      <td>930850.000000</td>\n",
       "      <td>930850.000000</td>\n",
       "      <td>930850.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.800785</td>\n",
       "      <td>103.069698</td>\n",
       "      <td>117.924126</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.970684</td>\n",
       "      <td>99.999968</td>\n",
       "      <td>101.920021</td>\n",
       "      <td>94.016914</td>\n",
       "      <td>99.998829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.244388</td>\n",
       "      <td>9.505444</td>\n",
       "      <td>5.845312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797564</td>\n",
       "      <td>0.018012</td>\n",
       "      <td>5.975187</td>\n",
       "      <td>0.589591</td>\n",
       "      <td>0.076508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       smart_1_normalized  smart_2_normalized  smart_3_normalized  \\\n",
       "count       930850.000000       930850.000000       930850.000000   \n",
       "mean            99.800785          103.069698          117.924126   \n",
       "std              1.244388            9.505444            5.845312   \n",
       "min             47.000000          100.000000          100.000000   \n",
       "25%            100.000000          100.000000          115.000000   \n",
       "50%            100.000000          100.000000          116.000000   \n",
       "75%            100.000000          100.000000          118.000000   \n",
       "max            100.000000          135.000000          253.000000   \n",
       "\n",
       "       smart_4_normalized  smart_5_normalized  smart_7_normalized  \\\n",
       "count            930850.0       930850.000000       930850.000000   \n",
       "mean                100.0           99.970684           99.999968   \n",
       "std                   0.0            0.797564            0.018012   \n",
       "min                 100.0           62.000000           84.000000   \n",
       "25%                 100.0          100.000000          100.000000   \n",
       "50%                 100.0          100.000000          100.000000   \n",
       "75%                 100.0          100.000000          100.000000   \n",
       "max                 100.0          100.000000          100.000000   \n",
       "\n",
       "       smart_8_normalized  smart_9_normalized  smart_10_normalized  \\\n",
       "count       930850.000000       930850.000000        930850.000000   \n",
       "mean           101.920021           94.016914            99.998829   \n",
       "std              5.975187            0.589591             0.076508   \n",
       "min             46.000000           93.000000            95.000000   \n",
       "25%            100.000000           94.000000           100.000000   \n",
       "50%            100.000000           94.000000           100.000000   \n",
       "75%            100.000000           94.000000           100.000000   \n",
       "max            123.000000           99.000000           100.000000   \n",
       "\n",
       "       smart_11_normalized          ...           smart_225_normalized  \\\n",
       "count                  0.0          ...                            0.0   \n",
       "mean                   NaN          ...                            NaN   \n",
       "std                    NaN          ...                            NaN   \n",
       "min                    NaN          ...                            NaN   \n",
       "25%                    NaN          ...                            NaN   \n",
       "50%                    NaN          ...                            NaN   \n",
       "75%                    NaN          ...                            NaN   \n",
       "max                    NaN          ...                            NaN   \n",
       "\n",
       "       smart_226_normalized  smart_240_normalized  smart_241_normalized  \\\n",
       "count                   0.0                   0.0                   0.0   \n",
       "mean                    NaN                   NaN                   NaN   \n",
       "std                     NaN                   NaN                   NaN   \n",
       "min                     NaN                   NaN                   NaN   \n",
       "25%                     NaN                   NaN                   NaN   \n",
       "50%                     NaN                   NaN                   NaN   \n",
       "75%                     NaN                   NaN                   NaN   \n",
       "max                     NaN                   NaN                   NaN   \n",
       "\n",
       "       smart_242_normalized  smart_250_normalized  smart_251_normalized  \\\n",
       "count                   0.0                   0.0                   0.0   \n",
       "mean                    NaN                   NaN                   NaN   \n",
       "std                     NaN                   NaN                   NaN   \n",
       "min                     NaN                   NaN                   NaN   \n",
       "25%                     NaN                   NaN                   NaN   \n",
       "50%                     NaN                   NaN                   NaN   \n",
       "75%                     NaN                   NaN                   NaN   \n",
       "max                     NaN                   NaN                   NaN   \n",
       "\n",
       "       smart_252_normalized  smart_254_normalized  smart_255_normalized  \n",
       "count                   0.0                   0.0                   0.0  \n",
       "mean                    NaN                   NaN                   NaN  \n",
       "std                     NaN                   NaN                   NaN  \n",
       "min                     NaN                   NaN                   NaN  \n",
       "25%                     NaN                   NaN                   NaN  \n",
       "50%                     NaN                   NaN                   NaN  \n",
       "75%                     NaN                   NaN                   NaN  \n",
       "max                     NaN                   NaN                   NaN  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain why we used range instead of variance, look at smart_1 and smart_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call (2) with the dataset df obtained with the previous call\n",
    "relevant_cols = find_relevant_cols(df) \n",
    "\n",
    "# Call (3) with the relevant columns relevant_cols    \n",
    "mask = build_mask(relevant_cols)    \n",
    "\n",
    "sum(mask) # Number of relevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have the mask relative to the model indicated in ModelName (ex:'Hitachi HDS722020ALA330'). \n",
    "\n",
    "We access the online data once again and save only the rows related to ModelName and the columns specified by the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [date, serial number, model, capacity, failure] + SMART metrics\n",
    "cols = [True, True, False, False, True] + mask \n",
    "\n",
    "# Path to the folder in which the datset will be stored\n",
    "folder_name_model = ModelName.replace(' ', '_')\n",
    "folder_name = 'Data/' + folder_name_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the data\n",
    "\n",
    "for year in [15,16,17] :\n",
    "    \n",
    "    df = read_model_and_rel_cols (ModelName, cols, dict_zipfile, year)\n",
    "    df.to_csv(folder_name + '/Model_' + str(year) + '.csv')\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
