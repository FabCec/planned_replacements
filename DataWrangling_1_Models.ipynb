{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  What hard-disk model shall we look at?\n",
    "\n",
    "### The SMART metrics present in the dataset are model-dependent, thus the various models have to be treated differently. In this project we will focus on a single model. \n",
    "\n",
    "With this script we aim to capture the most convenient model to focus on. We deduce that the model ST4000DM000 is the most used throughout 2015, 2016, and 2017 with 37600 differend hard disks of which about 7% have failed.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We load the datasets and extract the relevant columns and save them in ModelsDetail_15, ModelsDetail_16, and ModelsDetail_17. The relevant columns are :\n",
    "\n",
    "date : The time stamp of the observations.\n",
    "\n",
    "serial_number : Uniquely identifies a hard-disk. It is used to determine the number of distinct entries.\n",
    "\n",
    "model : Identifies the model of the hard-disk. \n",
    "\n",
    "failure : A value in {0,1}. When a 1 is present, the hard disk has failed on the specific date and is removed from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create empty list of dataframes with the data of 2015\n",
    "ListDF = []\n",
    "\n",
    "#Load data from 2015\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_2015.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('2015/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)\n",
    "    \n",
    "df = pd.concat(ListDF, ignore_index = True)\n",
    "\n",
    "#Compute entries and failures per model\n",
    "\n",
    "FailuresPerModel = df.groupby('model')['failure'].sum()\n",
    "EntriesPerModel = df.groupby('model')['serial_number'].unique()\n",
    "\n",
    "ModelsDetail_15 = pd.concat([EntriesPerModel,FailuresPerModel],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create empty list of dataframes with the data of 2016\n",
    "\n",
    "ListDF = []\n",
    "\n",
    "#Load data from 2016_Q1\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2016.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('data_Q1_2016/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)\n",
    "\n",
    "#Load data from 2016_Q2  \n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2016.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('data_Q2_2016/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)\n",
    "    \n",
    "#Load data from 2016_Q3\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2016.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('data_Q3_2016/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)    \n",
    "    \n",
    "#Load data from 2016_Q4\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q4_2016.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if name.endswith('.csv')]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)    \n",
    "      \n",
    "df = pd.concat(ListDF, ignore_index = True)\n",
    "\n",
    "#Compute entries and failures per model\n",
    "FailuresPerModel = df.groupby('model')['failure'].sum()\n",
    "EntriesPerModel = df.groupby('model')['serial_number'].unique()\n",
    "\n",
    "ModelsDetail_16 = pd.concat([EntriesPerModel,FailuresPerModel],axis=1)\n",
    "\n",
    "#ModelsDetail.to_csv('Data/Wrangled/ModelsDF_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create empty list of dataframes with the data of 2017\n",
    "ListDF = []\n",
    "\n",
    "#Load data from 2017_Q1\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2017.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if name.endswith('.csv')]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)    \n",
    "    \n",
    "    \n",
    "#Load data from 2017_Q2\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2017.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if name.endswith('.csv')]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)    \n",
    "    \n",
    "    \n",
    "#Load data from 2017_Q3\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2017.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if name.endswith('.csv')]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)    \n",
    "    \n",
    "       \n",
    "#Load data from 2017_Q4\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q4_2017.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('data_Q4_2017/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file))\n",
    "    data2 = data[['date','serial_number', 'model', 'failure']]\n",
    "    ListDF.append(data2)    \n",
    "        \n",
    "    \n",
    "df = pd.concat(ListDF, ignore_index = True)\n",
    "\n",
    "#Compute entries and failures per model\n",
    "\n",
    "FailuresPerModel = df.groupby('model')['failure'].sum()\n",
    "EntriesPerModel = df.groupby('model')['serial_number'].unique()\n",
    "\n",
    "ModelsDetail_17 = pd.concat([EntriesPerModel,FailuresPerModel],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For every year we saved the number of failures and an array of unique serial numbers\n",
    "\n",
    "We combine the information across the three years in a common dataset. Observe that the same hard disk may have been used across different years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ListDF_raw = [ModelsDetail_15.add_suffix('_15'), ModelsDetail_16.add_suffix('_16'), ModelsDetail_17.add_suffix('_17')]\n",
    "\n",
    "#df_raw = reduce(lambda x, y: pd.merge(x, y, on = 'model'), ListDF_raw)\n",
    "\n",
    "DfTot = pd.concat(ListDF_raw, axis = 1) \n",
    "\n",
    "DfTot.failure_15 = DfTot.failure_15.fillna(0) \n",
    "DfTot.failure_16 = DfTot.failure_16.fillna(0) \n",
    "DfTot.failure_17 = DfTot.failure_17.fillna(0) \n",
    "\n",
    "DfTot['failure_tot'] = DfTot.failure_15 + DfTot.failure_16 + DfTot.failure_17\n",
    "del DfTot['failure_15']\n",
    "del DfTot['failure_16']\n",
    "del DfTot['failure_17']\n",
    "\n",
    "DfTot['serial_number_tot'] = [np.hstack((DfTot.loc[mod,'serial_number_15'], DfTot.loc[mod,'serial_number_16'], DfTot.loc[mod,'serial_number_17'])) for mod in DfTot.index]\n",
    "\n",
    "del DfTot['serial_number_15']\n",
    "del DfTot['serial_number_16']\n",
    "del DfTot['serial_number_17']\n",
    "\n",
    "DfTot['entries_tot'] = [len(set(DfTot.loc[mod,'serial_number_tot'])) for mod in DfTot.index]\n",
    "\n",
    "del DfTot['serial_number_tot']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every model we have the number of distinct hard disks and the number of failures observed. \n",
    "We look at their ratio and filter the models for which too few hard disks have been sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failure_tot</th>\n",
       "      <th>entries_tot</th>\n",
       "      <th>ratio_entry_failures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WDC WD30EFRX</th>\n",
       "      <td>122.0</td>\n",
       "      <td>1261</td>\n",
       "      <td>0.096749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST3000DM001</th>\n",
       "      <td>106.0</td>\n",
       "      <td>1170</td>\n",
       "      <td>0.090598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST4000DM000</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>36700</td>\n",
       "      <td>0.070572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST31500541AS</th>\n",
       "      <td>112.0</td>\n",
       "      <td>1693</td>\n",
       "      <td>0.066155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi HDS723030ALA640</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.043222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi HDS722020ALA330</th>\n",
       "      <td>152.0</td>\n",
       "      <td>4683</td>\n",
       "      <td>0.032458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST6000DX000</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1938</td>\n",
       "      <td>0.030960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi HDS5C3030ALA630</th>\n",
       "      <td>96.0</td>\n",
       "      <td>4608</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi HDS5C4040ALE630</th>\n",
       "      <td>42.0</td>\n",
       "      <td>2660</td>\n",
       "      <td>0.015789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST8000DM002</th>\n",
       "      <td>141.0</td>\n",
       "      <td>10029</td>\n",
       "      <td>0.014059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGST HMS5C4040ALE640</th>\n",
       "      <td>97.0</td>\n",
       "      <td>8661</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGST HMS5C4040BLE640</th>\n",
       "      <td>135.0</td>\n",
       "      <td>16306</td>\n",
       "      <td>0.008279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST8000NM0055</th>\n",
       "      <td>88.0</td>\n",
       "      <td>14510</td>\n",
       "      <td>0.006065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST10000NM0086</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST12000NM0007</th>\n",
       "      <td>17.0</td>\n",
       "      <td>7244</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         failure_tot  entries_tot  ratio_entry_failures\n",
       "WDC WD30EFRX                   122.0         1261              0.096749\n",
       "ST3000DM001                    106.0         1170              0.090598\n",
       "ST4000DM000                   2590.0        36700              0.070572\n",
       "ST31500541AS                   112.0         1693              0.066155\n",
       "Hitachi HDS723030ALA640         44.0         1018              0.043222\n",
       "Hitachi HDS722020ALA330        152.0         4683              0.032458\n",
       "ST6000DX000                     60.0         1938              0.030960\n",
       "Hitachi HDS5C3030ALA630         96.0         4608              0.020833\n",
       "Hitachi HDS5C4040ALE630         42.0         2660              0.015789\n",
       "ST8000DM002                    141.0        10029              0.014059\n",
       "HGST HMS5C4040ALE640            97.0         8661              0.011200\n",
       "HGST HMS5C4040BLE640           135.0        16306              0.008279\n",
       "ST8000NM0055                    88.0        14510              0.006065\n",
       "ST10000NM0086                    3.0         1225              0.002449\n",
       "ST12000NM0007                   17.0         7244              0.002347"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DfTot['ratio_entry_failures'] = DfTot['failure_tot'].divide(DfTot['entries_tot'], axis = 'rows')\n",
    "DfTot.sort_values('ratio_entry_failures', inplace=True, ascending =False)\n",
    "\n",
    "DfTot[DfTot['entries_tot'] > 1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
