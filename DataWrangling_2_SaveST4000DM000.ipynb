{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataset associated to the model ST4000DM000.\n",
    "\n",
    "Every model is associated with different SMART metrics. Moreover, for every relevant SMART metric we will work with the normalized value (in between 0 and 100/200/260 depending on the metric, the higher the better in tems of performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NonNullCols has a True value in correspondence of a column we want to save\n",
    "\n",
    "NonNullCols = [ True,  True,  False,  False,  True, # date, serial number, model, capacity, failure\n",
    "                False, False, False, False, False, False,  False, False, # SMART 1 - 2 - 3 - 4 \n",
    "                True,  False, True,  False, False, False,  True,  False, # SMART 5 - 7 - 8 - 9 \n",
    "                False, False, False, False, False, False,  False, False, # SMART 10 - 11 - 12 -13\n",
    "                False, False, False, False, True,  False,  False, False, # SMART 15 - 22 - 183 - 184 \n",
    "                True,  False, False, False, True,  False,  True,  False, # SMART 187 - 188 - 189 - 190\n",
    "                False, False, False, False, True,  False,  True,  False, # SMART 191 - 192 - 193 - 194 \n",
    "                False, False, False, False, True,  False,  True,  False, # SMART 195 - 196 - 197 - 198 \n",
    "                False, False, False, False, False, False,  False, False, # SMART 199 - 200 - 201 - 220\n",
    "                False, False, False, False, False, False,  False, False, # SMART 222 - 223 - 224 - 225\n",
    "                False, False, False, False, False, False,  False, False, # SMART 226 - 240 - 241 - 242\n",
    "                False, False, False, False, False, False,  False, False, False, False] # SMART 250 - 251 - 252 - 254 - 255\n",
    "\n",
    "# model and capacity are constant when we select only model ST4000DM000\n",
    "\n",
    "# SMART 2 - 8 - 11 - 13 - 15 - 22 - 195 - 196 - 200 - 201 - 220 - 222 - 223 - 224 - 225 - 226 - 250 - 251 - 252 - 254 - 255\n",
    "# Are not present for model ST4000DM000\n",
    "\n",
    "# SMART 1 - 3 - 4 - 10 - 12 - 184 - 188 - 191 - 192 - 199 - 240 - 241 - 242 \n",
    "# Have a very low (some null) variance across the 2015 dataset and those columns are removed as well from the \n",
    "\n",
    "ModelName = 'ST4000DM000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each year we maintain 14 columns (date, serial_number, failure and 11 normalized SMART metrics)\n",
    "\n",
    "The resulting datasets are saved and have the following features:\n",
    "\n",
    "2015 : 6.8  Millions of rows and 0.6GB of space\n",
    "\n",
    "2016 : 12.4 Millions of rows and 1.1GB of space\n",
    "\n",
    "2017 : 12.2 Millions of rows and 1.1GB of space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ListDF_ST = []\n",
    "\n",
    "#Load data from 2015\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_2015.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('2015/'))]   \n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)\n",
    "    \n",
    "df = pd.concat(ListDF_ST, ignore_index = True)\n",
    "df.to_csv('Data/Wrangled/STModel_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ListDF_ST = []\n",
    "\n",
    "#Load data from 2016_Q1\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2016.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('data_Q1_2016/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)\n",
    "\n",
    "#Load data from 2016_Q2  \n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2016.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('data_Q2_2016/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)\n",
    "    \n",
    "#Load data from 2016_Q3\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2016.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('data_Q3_2016/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)    \n",
    "    \n",
    "#Load data from 2016_Q4\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q4_2016.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if name.endswith('.csv')]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)\n",
    "    \n",
    "df = pd.concat(ListDF_ST, ignore_index = True)\n",
    "df.to_csv('Data/Wrangled/STModel_16.csv')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ListDF_ST = []\n",
    "\n",
    "#Load data from 2017_Q1\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2017.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if name.endswith('.csv')]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)  \n",
    "    \n",
    "    \n",
    "#Load data from 2017_Q2\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2017.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if name.endswith('.csv')]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)\n",
    "    \n",
    "    \n",
    "#Load data from 2017_Q3\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2017.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if name.endswith('.csv')]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)\n",
    "    \n",
    "       \n",
    "#Load data from 2017_Q4\n",
    "\n",
    "r = requests.get('https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q4_2017.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "files = [name for name in z.namelist() if (name.endswith('.csv')) & (name.startswith('data_Q4_2017/'))]\n",
    "\n",
    "for file in files : \n",
    "    data = pd.read_csv(z.open(file), parse_dates = [0])\n",
    "    data2 = data[data['model'] == ModelName]\n",
    "    data3 = data2.iloc[:,NonNullCols]\n",
    "    ListDF_ST.append(data3)    \n",
    "    \n",
    "    \n",
    "df = pd.concat(ListDF_ST, ignore_index = True)\n",
    "df.to_csv('Data/Wrangled/STModel_17.csv')     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
